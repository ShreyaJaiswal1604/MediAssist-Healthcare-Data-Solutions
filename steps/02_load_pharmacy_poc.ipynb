{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "AUTOMATE TEST SCRIPT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'DOLPHIN'\n",
    "password = 'Maapaa@1603'  # Avoid hardcoding sensitive information\n",
    "account = 'URB63596'\n",
    "database = 'mimic_iv_medi_assist'\n",
    "schema = 'raw'\n",
    "warehouse = 'my_warehouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowpark_basic_auth() -> Session:\n",
    "    connection_parameters = {\n",
    "        \"ACCOUNT\":\"URB63596\",\n",
    "        \"USER\":\"DOLPHIN\",\n",
    "        \"PASSWORD\":\"Maapaa@1603\"\n",
    "    }\n",
    "    return Session.builder.configs(connection_parameters).create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ddl_statement(column_names, data_types, table_name):\n",
    "    ddl_template = \"CREATE TABLE IF NOT EXISTS {} (\\n{})\"\n",
    "    columns = []\n",
    "    for name, data_type in zip(column_names, data_types):\n",
    "        column_definition = f\"   {name} {data_type}\"\n",
    "        columns.append(column_definition)\n",
    "\n",
    "    ddl_statement = ddl_template.format(table_name, \",\\n\".join(columns))\n",
    "    return ddl_statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_copy_statement(table_name,stage_name,csv_file_path,file_format):\n",
    "    copy_command = f\"\"\"\n",
    "    COPY INTO {table_name}\n",
    "    FROM @{stage_name}/{csv_file_path}\n",
    "    FILE_FORMAT = (FORMAT_NAME = '{file_format}')\n",
    "    ;\n",
    "    \"\"\"\n",
    "\n",
    "    return copy_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_format(session):\n",
    "    print(\"Creating file format...\")\n",
    "    session.sql(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT file_format_csv\n",
    "        TYPE = 'CSV'\n",
    "        COMPRESSION = 'GZIP'                   -- Specify GZIP compression for .gz files\n",
    "        FIELD_DELIMITER = ','                   -- Specify the field delimiter\n",
    "        PARSE_HEADER = TRUE                      -- Parse the header row for column names\n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"';     -- Optional field enclosure\n",
    "    \"\"\").collect()\n",
    "\n",
    "    print(\"File format 'file_format_csv' created successfully.\")\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_format(session):\n",
    "    print(\"Creating file format for DDL...\")\n",
    "    session.sql(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT file_format_ddl\n",
    "        TYPE = 'CSV'\n",
    "        COMPRESSION = 'GZIP'                   -- Specify GZIP compression for .gz files\n",
    "        FIELD_DELIMITER = ','                   -- Specify the field delimiter\n",
    "        PARSE_HEADER = TRUE                    -- Parse the header row for column names\n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "        ESCAPE_UNENCLOSED_FIELD = NONE \n",
    "        TRIM_SPACE = TRUE \n",
    "        ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE;\n",
    "    \"\"\").collect()\n",
    "\n",
    "    print(\"File format 'file_format_ddl' created successfully.\")\n",
    "    print(\"===========\")\n",
    "\n",
    "    session.sql(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT file_format_load\n",
    "        TYPE = 'CSV'\n",
    "        COMPRESSION = 'auto'                   \n",
    "        FIELD_DELIMITER = ','                   \n",
    "        RECORD_DELIMITER = '\\n'\n",
    "        SKIP_HEADER = 1                      \n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "        NULL_IF = ('NA', 'NULL', '')\n",
    "        ESCAPE_UNENCLOSED_FIELD = None;\n",
    "    \"\"\").collect()\n",
    "\n",
    "    print(\"File format 'file_format_load' created successfully.\")\n",
    "    print(\"===========\")\n",
    "\n",
    "    session.sql(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT file_format_generic\n",
    "        TYPE = 'CSV'\n",
    "        COMPRESSION = 'GZIP'\n",
    "        FIELD_DELIMITER = ','\n",
    "        PARSE_HEADER = TRUE\n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "        ESCAPE_UNENCLOSED_FIELD = None;\n",
    "    \"\"\").collect()\n",
    "\n",
    "    print(\"File format 'file_format_generic' created successfully.\")\n",
    "    print(\"===========\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file format for DDL...\n",
      "File format 'file_format_ddl' created successfully.\n",
      "===========\n",
      "File format 'file_format_load' created successfully.\n",
      "===========\n",
      "File format 'file_format_generic' created successfully.\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "utc_start_time = datetime.utcnow()\n",
    "session_wih_pwd = snowpark_basic_auth()\n",
    "\n",
    "\n",
    "session_wih_pwd.sql(\"USE DATABASE mimic_iv_medi_assist\").collect()\n",
    "session_wih_pwd.sql(\"USE SCHEMA raw\").collect()\n",
    "session_wih_pwd.sql(\"USE WAREHOUSE my_warehouse\").collect()\n",
    "\n",
    "create_file_format(session_wih_pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='my_internal_stage_csv/admissions.csv.gz', size=19652448, md5='ca4c01f1ed192dc9f37610788e55b9c2', last_modified='Wed, 6 Nov 2024 19:21:28 GMT'), Row(name='my_internal_stage_csv/d_icd_diagnoses.csv.gz', size=849392, md5='338e8df872c0072303fab34363477205', last_modified='Wed, 6 Nov 2024 19:37:21 GMT'), Row(name='my_internal_stage_csv/d_icd_procedures.csv.gz', size=549936, md5='11334a60784998d1b55ffb70c85747a2', last_modified='Wed, 6 Nov 2024 19:37:43 GMT'), Row(name='my_internal_stage_csv/discharge.csv.gz', size=1138613360, md5='f3444a3b359d3b77e12bc5c776794605-136', last_modified='Wed, 6 Nov 2024 18:57:04 GMT'), Row(name='my_internal_stage_csv/drgcodes.csv.gz', size=9509520, md5='c67e79b9f576a0732175f4ed03279ab2', last_modified='Wed, 6 Nov 2024 19:25:50 GMT'), Row(name='my_internal_stage_csv/pharmacy.csv.gz', size=512995568, md5='1646a64f34493f9df88c90b545d32d8e-62', last_modified='Wed, 6 Nov 2024 15:38:46 GMT'), Row(name='my_internal_stage_csv/pharmacy_sample.csv.gz', size=496, md5='6dfb48039d1bfffad271b0299c881820', last_modified='Wed, 6 Nov 2024 18:09:32 GMT')]\n"
     ]
    }
   ],
   "source": [
    "stg_files = session_wih_pwd.sql(\"list @my_internal_stage_csv\").collect()\n",
    "print(stg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started at: 2024-11-06 19:38:31.352171\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/admissions.csv.gz', size=19652448, md5='ca4c01f1ed192dc9f37610788e55b9c2', last_modified='Wed, 6 Nov 2024 19:21:28 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/admissions.csv.gz', 'size': 19652448, 'md5': 'ca4c01f1ed192dc9f37610788e55b9c2', 'last_modified': 'Wed, 6 Nov 2024 19:21:28 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/admissions.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: admissions.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/d_icd_diagnoses.csv.gz', size=849392, md5='338e8df872c0072303fab34363477205', last_modified='Wed, 6 Nov 2024 19:37:21 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/d_icd_diagnoses.csv.gz', 'size': 849392, 'md5': '338e8df872c0072303fab34363477205', 'last_modified': 'Wed, 6 Nov 2024 19:37:21 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/d_icd_diagnoses.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: d_icd_diagnoses.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "Processing target file: d_icd_diagnoses.csv.gz\n",
      "\n",
      "=========== INFER SCHEMA SQL =============\n",
      "File: d_icd_diagnoses.csv.gz\n",
      "        SELECT * \n",
      "        FROM TABLE(\n",
      "            INFER_SCHEMA(\n",
      "            LOCATION=>'@my_internal_stage_csv/',\n",
      "            files => 'd_icd_diagnoses.csv.gz',\n",
      "            FILE_FORMAT => 'file_format_ddl'\n",
      "        )    \n",
      "    )\n",
      "    \n",
      "\n",
      "Schema inference completed. Inferred schema rows:\n",
      "[Row(COLUMN_NAME='icd_code', TYPE='TEXT', NULLABLE=True, EXPRESSION='$1::TEXT', FILENAMES='d_icd_diagnoses.csv.gz', ORDER_ID=0), Row(COLUMN_NAME='icd_version', TYPE='NUMBER(2, 0)', NULLABLE=True, EXPRESSION='$2::NUMBER(2, 0)', FILENAMES='d_icd_diagnoses.csv.gz', ORDER_ID=1), Row(COLUMN_NAME='long_title', TYPE='TEXT', NULLABLE=True, EXPRESSION='$3::TEXT', FILENAMES='d_icd_diagnoses.csv.gz', ORDER_ID=2)]\n",
      "Inferred schema row: {'COLUMN_NAME': 'icd_code', 'TYPE': 'TEXT', 'NULLABLE': True, 'EXPRESSION': '$1::TEXT', 'FILENAMES': 'd_icd_diagnoses.csv.gz', 'ORDER_ID': 0}\n",
      "Inferred schema row: {'COLUMN_NAME': 'icd_version', 'TYPE': 'NUMBER(2, 0)', 'NULLABLE': True, 'EXPRESSION': '$2::NUMBER(2, 0)', 'FILENAMES': 'd_icd_diagnoses.csv.gz', 'ORDER_ID': 1}\n",
      "Inferred schema row: {'COLUMN_NAME': 'long_title', 'TYPE': 'TEXT', 'NULLABLE': True, 'EXPRESSION': '$3::TEXT', 'FILENAMES': 'd_icd_diagnoses.csv.gz', 'ORDER_ID': 2}\n",
      "Column names list: ['icd_code', 'icd_version', 'long_title']\n",
      "Column data types list: ['TEXT', 'NUMBER(2, 0)', 'TEXT']\n",
      "=================== DDL STATEMENT =====================\n",
      "CREATE TABLE IF NOT EXISTS D_ICD_DIAGNOSES_RAW_POC (\n",
      "   icd_code TEXT,\n",
      "   icd_version NUMBER(2, 0),\n",
      "   long_title TEXT)\n",
      "=================== COPY STATEMENT =====================\n",
      "\n",
      "    COPY INTO d_icd_diagnoses_raw_poc\n",
      "    FROM @my_internal_stage_csv/d_icd_diagnoses.csv.gz\n",
      "    FILE_FORMAT = (FORMAT_NAME = 'file_format_load')\n",
      "    ;\n",
      "    \n",
      "=================== SQL FILE PATH =====================\n",
      "File path for saving SQL: d_icd_diagnoses_raw_poc.sql\n",
      "SQL statements written to file: d_icd_diagnoses_raw_poc.sql\n",
      "Table created successfully with DDL statement.\n",
      "Data loaded into the table with COPY statement.\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/d_icd_procedures.csv.gz', size=549936, md5='11334a60784998d1b55ffb70c85747a2', last_modified='Wed, 6 Nov 2024 19:37:43 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/d_icd_procedures.csv.gz', 'size': 549936, 'md5': '11334a60784998d1b55ffb70c85747a2', 'last_modified': 'Wed, 6 Nov 2024 19:37:43 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/d_icd_procedures.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: d_icd_procedures.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "Processing target file: d_icd_procedures.csv.gz\n",
      "\n",
      "=========== INFER SCHEMA SQL =============\n",
      "File: d_icd_procedures.csv.gz\n",
      "        SELECT * \n",
      "        FROM TABLE(\n",
      "            INFER_SCHEMA(\n",
      "            LOCATION=>'@my_internal_stage_csv/',\n",
      "            files => 'd_icd_procedures.csv.gz',\n",
      "            FILE_FORMAT => 'file_format_ddl'\n",
      "        )    \n",
      "    )\n",
      "    \n",
      "\n",
      "Schema inference completed. Inferred schema rows:\n",
      "[Row(COLUMN_NAME='icd_code', TYPE='TEXT', NULLABLE=True, EXPRESSION='$1::TEXT', FILENAMES='d_icd_procedures.csv.gz', ORDER_ID=0), Row(COLUMN_NAME='icd_version', TYPE='NUMBER(2, 0)', NULLABLE=True, EXPRESSION='$2::NUMBER(2, 0)', FILENAMES='d_icd_procedures.csv.gz', ORDER_ID=1), Row(COLUMN_NAME='long_title', TYPE='TEXT', NULLABLE=True, EXPRESSION='$3::TEXT', FILENAMES='d_icd_procedures.csv.gz', ORDER_ID=2)]\n",
      "Inferred schema row: {'COLUMN_NAME': 'icd_code', 'TYPE': 'TEXT', 'NULLABLE': True, 'EXPRESSION': '$1::TEXT', 'FILENAMES': 'd_icd_procedures.csv.gz', 'ORDER_ID': 0}\n",
      "Inferred schema row: {'COLUMN_NAME': 'icd_version', 'TYPE': 'NUMBER(2, 0)', 'NULLABLE': True, 'EXPRESSION': '$2::NUMBER(2, 0)', 'FILENAMES': 'd_icd_procedures.csv.gz', 'ORDER_ID': 1}\n",
      "Inferred schema row: {'COLUMN_NAME': 'long_title', 'TYPE': 'TEXT', 'NULLABLE': True, 'EXPRESSION': '$3::TEXT', 'FILENAMES': 'd_icd_procedures.csv.gz', 'ORDER_ID': 2}\n",
      "Column names list: ['icd_code', 'icd_version', 'long_title']\n",
      "Column data types list: ['TEXT', 'NUMBER(2, 0)', 'TEXT']\n",
      "=================== DDL STATEMENT =====================\n",
      "CREATE TABLE IF NOT EXISTS D_ICD_PROCEDURES_RAW_POC (\n",
      "   icd_code TEXT,\n",
      "   icd_version NUMBER(2, 0),\n",
      "   long_title TEXT)\n",
      "=================== COPY STATEMENT =====================\n",
      "\n",
      "    COPY INTO d_icd_procedures_raw_poc\n",
      "    FROM @my_internal_stage_csv/d_icd_procedures.csv.gz\n",
      "    FILE_FORMAT = (FORMAT_NAME = 'file_format_load')\n",
      "    ;\n",
      "    \n",
      "=================== SQL FILE PATH =====================\n",
      "File path for saving SQL: d_icd_procedures_raw_poc.sql\n",
      "SQL statements written to file: d_icd_procedures_raw_poc.sql\n",
      "Table created successfully with DDL statement.\n",
      "Data loaded into the table with COPY statement.\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/discharge.csv.gz', size=1138613360, md5='f3444a3b359d3b77e12bc5c776794605-136', last_modified='Wed, 6 Nov 2024 18:57:04 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/discharge.csv.gz', 'size': 1138613360, 'md5': 'f3444a3b359d3b77e12bc5c776794605-136', 'last_modified': 'Wed, 6 Nov 2024 18:57:04 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/discharge.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: discharge.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/drgcodes.csv.gz', size=9509520, md5='c67e79b9f576a0732175f4ed03279ab2', last_modified='Wed, 6 Nov 2024 19:25:50 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/drgcodes.csv.gz', 'size': 9509520, 'md5': 'c67e79b9f576a0732175f4ed03279ab2', 'last_modified': 'Wed, 6 Nov 2024 19:25:50 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/drgcodes.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: drgcodes.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/pharmacy.csv.gz', size=512995568, md5='1646a64f34493f9df88c90b545d32d8e-62', last_modified='Wed, 6 Nov 2024 15:38:46 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/pharmacy.csv.gz', 'size': 512995568, 'md5': '1646a64f34493f9df88c90b545d32d8e-62', 'last_modified': 'Wed, 6 Nov 2024 15:38:46 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/pharmacy.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: pharmacy.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "======================================================\n",
      "\n",
      "Processing row: Row(name='my_internal_stage_csv/pharmacy_sample.csv.gz', size=496, md5='6dfb48039d1bfffad271b0299c881820', last_modified='Wed, 6 Nov 2024 18:09:32 GMT')\n",
      "Row as dictionary: {'name': 'my_internal_stage_csv/pharmacy_sample.csv.gz', 'size': 496, 'md5': '6dfb48039d1bfffad271b0299c881820', 'last_modified': 'Wed, 6 Nov 2024 18:09:32 GMT'}\n",
      "Staged file path value: my_internal_stage_csv/pharmacy_sample.csv.gz\n",
      "File path: my_internal_stage_csv\n",
      "File name: pharmacy_sample.csv.gz\n",
      "Staged location: @my_internal_stage_csv\n",
      "Process completed at: 2024-11-06 19:38:37.519959\n",
      "Total processing time: 0:00:06.167788\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "utc_start_time = datetime.utcnow()\n",
    "print(\"Process started at:\", utc_start_time)\n",
    "\n",
    "for row in stg_files:\n",
    "    print(\"======================================================\\n\")\n",
    "    print(\"Processing row:\", row)\n",
    "    \n",
    "    # Convert row to dictionary\n",
    "    row_value = row.as_dict()\n",
    "    print(\"Row as dictionary:\", row_value)\n",
    "    \n",
    "    # Extract the staged file path value\n",
    "    stg_file_path_value = row_value.get('name')\n",
    "    print(\"Staged file path value:\", stg_file_path_value)\n",
    "\n",
    "    # Split file path and name\n",
    "    file_path, file_name = os.path.split(stg_file_path_value)\n",
    "    print(\"File path:\", file_path)\n",
    "    print(\"File name:\", file_name)\n",
    "\n",
    "    # Create staged location variable\n",
    "    stg_location = \"@\" + file_path\n",
    "    print(\"Staged location:\", stg_location)\n",
    "\n",
    "    # Filter for specific file\n",
    "    if file_name not in ('d_icd_procedures.csv.gz, d_icd_diagnoses.csv.gz'):\n",
    "        #print(f\"Skipping file {file_name} as it doesn't match the target file.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing target file: {file_name}\")\n",
    "    \n",
    "    # Generate SQL for inferring schema\n",
    "    infer_schema_sql = \"\"\"\\\n",
    "        SELECT * \n",
    "        FROM TABLE(\n",
    "            INFER_SCHEMA(\n",
    "            LOCATION=>'{}/',\n",
    "            files => '{}',\n",
    "            FILE_FORMAT => 'file_format_ddl'\n",
    "        )    \n",
    "    )\n",
    "    \"\"\".format(stg_location, file_name)\n",
    "    \n",
    "    print(\"\\n=========== INFER SCHEMA SQL =============\")\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(infer_schema_sql)\n",
    "\n",
    "    # Execute schema inference\n",
    "    inferred_schema_rows = session_wih_pwd.sql(infer_schema_sql).collect()\n",
    "    print(\"\\nSchema inference completed. Inferred schema rows:\")\n",
    "    print(inferred_schema_rows)\n",
    "\n",
    "    # Prepare lists for column names and types\n",
    "    col_name_lst = []\n",
    "    col_data_type_lst = []\n",
    "\n",
    "    # Process each row in inferred schema\n",
    "    for row in inferred_schema_rows:\n",
    "        row_value = row.as_dict()\n",
    "        print(\"Inferred schema row:\", row_value)\n",
    "        \n",
    "        column_name = row_value.get('COLUMN_NAME')\n",
    "        column_type = row_value.get('TYPE')\n",
    "\n",
    "        col_name_lst.append(column_name)\n",
    "        col_data_type_lst.append(column_type)\n",
    "\n",
    "    print(\"Column names list:\", col_name_lst)\n",
    "    print(\"Column data types list:\", col_data_type_lst)\n",
    "\n",
    "    # Generate table name and DDL statement\n",
    "    table_name = file_name.split('.')[0] + \"_raw_poc\"\n",
    "    create_ddl_stmt = generate_ddl_statement(col_name_lst, col_data_type_lst, table_name.upper())\n",
    "    print(\"=================== DDL STATEMENT =====================\")\n",
    "    print(create_ddl_stmt)\n",
    "\n",
    "    # Generate copy statement for loading data\n",
    "    copy_stmt = generate_copy_statement(table_name, 'my_internal_stage_csv', file_name, 'file_format_load')\n",
    "    print(\"=================== COPY STATEMENT =====================\")\n",
    "    print(copy_stmt)\n",
    "\n",
    "    # Define SQL file path and save DDL and copy statements to file\n",
    "    sql_file_path = table_name + \".sql\"\n",
    "    print(\"=================== SQL FILE PATH =====================\")\n",
    "    print(\"File path for saving SQL:\", sql_file_path)\n",
    "    with open(sql_file_path, \"w\") as sql_file:\n",
    "        sql_file.write(\"---- Following statement is creating table\\n\\n\")\n",
    "        sql_file.write(create_ddl_stmt)\n",
    "        sql_file.write(\"\\n-- Following statement is executing copy command\\n\")\n",
    "        sql_file.write(copy_stmt)\n",
    "    print(\"SQL statements written to file:\", sql_file_path)\n",
    "\n",
    "    # Execute DDL to create the table\n",
    "    session_wih_pwd.sql(create_ddl_stmt).collect()\n",
    "    print(\"Table created successfully with DDL statement.\")\n",
    "\n",
    "    # Execute copy command to load data into the table\n",
    "    session_wih_pwd.sql(copy_stmt).collect()\n",
    "    print(\"Data loaded into the table with COPY statement.\")\n",
    "\n",
    "# End of processing and time calculation\n",
    "utc_end_time = datetime.utcnow()\n",
    "print(\"Process completed at:\", utc_end_time)\n",
    "print(\"Total processing time:\", utc_end_time - utc_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
