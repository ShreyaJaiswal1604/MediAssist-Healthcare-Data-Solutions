{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI READ\n",
    "\n",
    "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\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake connection details\n",
    "SNOWFLAKE_USER = \"DOLPHIN\"\n",
    "SNOWFLAKE_PASSWORD = \"Maapaa@1603\"\n",
    "SNOWFLAKE_ACCOUNT = \"URB63596\"\n",
    "SNOWFLAKE_WAREHOUSE = \"ANIMAL_TASK_WH\"\n",
    "SNOWFLAKE_DATABASE = \"mimic_iv_medi_assist\"\n",
    "SNOWFLAKE_SCHEMA = \"staging_mimc\"\n",
    "DISCHARGE_TABLE = \"MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex AI endpoint details\n",
    "PROJECT_ID = \"168237001903\"  # Replace with your GCP Project ID\n",
    "ENDPOINT_ID = \"2125990394700234752\"  # Replace with your Endpoint ID\n",
    "LOCATION = \"us-central1\"  # Replace with your endpoint region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "MODEL - ruslanmv/Medical-Llama3-8B (Version 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to extract clinical discharge notes\n",
    "QUERY = \"\"\"\n",
    "SELECT SUBJECT_ID, HADM_ID, TEXT \n",
    "FROM MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\n",
    "WHERE TEXT IS NOT NULL\n",
    "LIMIT 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, max_length=1024):\n",
    "    \"\"\"\n",
    "    Truncates the input text to ensure it fits within the model's token limit.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input clinical note.\n",
    "        max_length (int): Maximum allowed length for the text in tokens.\n",
    "\n",
    "    Returns:\n",
    "        str: The truncated text.\n",
    "    \"\"\"\n",
    "    truncated = text[:max_length]\n",
    "    print(f\"Truncated text to {len(truncated)} characters (max {max_length}).\")\n",
    "    return truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch clinical notes from Snowflake\n",
    "def fetch_clinical_notes():\n",
    "    try:\n",
    "        # Connect to Snowflake\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "        )\n",
    "        # Execute the query and fetch results\n",
    "        df = pd.read_sql(QUERY, conn)\n",
    "        conn.close()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from Snowflake: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instance(note):\n",
    "    \"\"\"\n",
    "    Formats the clinical note with an instruction for ICD-10 code generation.\n",
    "\n",
    "    Args:\n",
    "        note (str): The input clinical note.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted instance for the model.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a clinical language model specialized in generating ICD-10 codes.\n",
    "    Below is a clinical note. Analyze it and generate the top 10 most relevant ICD-10 codes.\n",
    "\n",
    "    Clinical Note:\n",
    "    {note}\n",
    "\n",
    "    Please return the ICD-10 codes as a Python list of strings.\n",
    "    \"\"\"\n",
    "    print(f\"Formatted prompt: {prompt[:200]}...\")  # Display the first 200 characters for debugging\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom_trained_model_sample(project, endpoint_id, location, instances):\n",
    "    try:\n",
    "        # Initialize the Vertex AI Prediction client\n",
    "        aiplatform.init(project=project, location=location)\n",
    "\n",
    "        # Load the endpoint\n",
    "        endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project}/locations/{location}/endpoints/{endpoint_id}\")\n",
    "\n",
    "        # Format the payload to match the expected input structure with truncation\n",
    "        formatted_instances = [{\"inputs\": truncate_text(instance[\"input\"])} for instance in instances]\n",
    "\n",
    "\n",
    "        # Send the prediction request\n",
    "        response = endpoint.predict(instances=formatted_instances)\n",
    "\n",
    "        # Extract the predictions\n",
    "        return response.predictions\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating predictions: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_icd_codes(project, endpoint_id, location, instances):\n",
    "    \"\"\"\n",
    "    Sends clinical notes to a Vertex AI endpoint and retrieves ICD-10 code predictions.\n",
    "\n",
    "    Args:\n",
    "        project (str): GCP project ID.\n",
    "        endpoint_id (str): Vertex AI endpoint ID.\n",
    "        location (str): Location of the endpoint (e.g., \"us-central1\").\n",
    "        instances (list): List of clinical notes to process.\n",
    "\n",
    "    Returns:\n",
    "        list: Predictions from the model, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\nInitializing Vertex AI client...\")\n",
    "        aiplatform.init(project=project, location=location)\n",
    "\n",
    "        # Load the endpoint\n",
    "        print(f\"Loading endpoint: projects/{project}/locations/{location}/endpoints/{endpoint_id}\")\n",
    "        endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project}/locations/{location}/endpoints/{endpoint_id}\")\n",
    "\n",
    "        # Format the payload with instructions\n",
    "        print(\"Formatting instances with instructions for ICD-10 code generation...\")\n",
    "        formatted_instances = [{\"inputs\": truncate_text(format_instance(instance[\"input\"]), max_length=896)} for instance in instances]\n",
    "\n",
    "        # Send the prediction request\n",
    "        print(\"Sending prediction request to the endpoint...\")\n",
    "        response = endpoint.predict(\n",
    "            instances=formatted_instances,\n",
    "            parameters={\"max_new_tokens\": 128}  # Reserve tokens for output\n",
    "        )\n",
    "\n",
    "        # Extract predictions\n",
    "        print(f\"Predictions received: {response.predictions}\")\n",
    "        return response.predictions\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error generating predictions: {error}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_clinical_notes():\n",
    "    \"\"\"\n",
    "    Fetches clinical notes from the Snowflake database.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame containing the clinical notes.\n",
    "    \"\"\"\n",
    "    # Snowflake connection details\n",
    "# Snowflake connection details\n",
    "    SNOWFLAKE_USER = \"DOLPHIN\"\n",
    "    SNOWFLAKE_PASSWORD = \"Maapaa@1603\"\n",
    "    SNOWFLAKE_ACCOUNT = \"URB63596\"\n",
    "    SNOWFLAKE_WAREHOUSE = \"ANIMAL_TASK_WH\"\n",
    "    SNOWFLAKE_DATABASE = \"mimic_iv_medi_assist\"\n",
    "    SNOWFLAKE_SCHEMA = \"staging_mimc\"\n",
    "    DISCHARGE_TABLE = \"MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT SUBJECT_ID, HADM_ID, TEXT \n",
    "    FROM MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\n",
    "    WHERE TEXT IS NOT NULL\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(\"\\nConnecting to Snowflake...\")\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "        )\n",
    "        print(\"Executing query to fetch clinical notes...\")\n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        print(f\"Fetched {len(df)} records from Snowflake.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from Snowflake: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ICD-10 Code Prediction Workflow...\n",
      "\n",
      "Step 1: Fetching clinical notes...\n",
      "\n",
      "Connecting to Snowflake...\n",
      "Executing query to fetch clinical notes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/v5dnvjg12ws3p1zszn_fvgt80000gn/T/ipykernel_6027/2574269206.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1 records from Snowflake.\n",
      "Step 2: Processing clinical notes...\n",
      "\n",
      "Processing SUBJECT_ID: 15992303, HADM_ID: 22502053\n",
      "Clinical Note:  \n",
      "Name:  ___               Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Amoxicillin / azithromy...\n",
      "\n",
      "Initializing Vertex AI client...\n",
      "Loading endpoint: projects/168237001903/locations/us-central1/endpoints/2125990394700234752\n",
      "Formatting instances with instructions for ICD-10 code generation...\n",
      "Formatted prompt: \n",
      "    You are a clinical language model specialized in generating ICD-10 codes.\n",
      "    Below is a clinical note. Analyze it and generate the top 10 most relevant ICD-10 codes.\n",
      "\n",
      "    Clinical Note:\n",
      "     \n",
      "Na...\n",
      "Truncated text to 896 characters (max 896).\n",
      "Sending prediction request to the endpoint...\n",
      "Predictions received: ['04 therapy, so after evaluation with characteristic\\nradiographic findings in the liver, transplutaminase and AST\\nsubsequently increased to 1200. Evaluation at the care unit indicated\\nelevated CRP, N/A and ferritin of 80. C. Hepatitis markers are positive\\nincluding S100, and 18-alpha globulin and IgM. Stones have been found\\non repeat parenchyma. \\n\\n     \\nPatient is scheduled for operative repair as emergency.\\n     \\nDignosed with Hepatitis A. \\n     \\nPractice Notes:\\nHepanmarerecapaderance \\nComplicacionssopomolardwasden arrivingin aspectos0\\nnasopharyngal sphere. Continued laparoscopic perforantenen on\\nA taper, and using regular 0,5 mg\\n\\n\\n     \\n          Status Post\\n       Liver Biopsy. NOTE:** long-term renal dialysis\\n       (ME).\\n       (ME)\\n       Stat\\n       Note:** **\\n     \\n           _______________________\\n   \\n \\n\\nSignals are more important than words in generating ICD codes\\n\\nFrontOpt: Elastic Forward Semantic Search in Scientific Paper Networks-With Dr L____ S______ from Stanford University\\n\\nStataware Internship:\\n\\nTill you learn, I’ll teach\\nThis place requires training its hardtakers\\n\\nTree plotting module: With Dr. J____ H____Yellowing of trees: replikaemonnode  (Forked to Fletcher NIH)\\n\\nMacroeconomic data visualisation: With Dr. L____ H____ teclusigent\\n\\nThe opportunity: RAI\\nauto generate ICD codes with the narrative text\\n\\nRais presentation\\nThe inaugaration\\n\\nAs a visual designer (Box free)\\nAs testing manager (same repo, with public key access).\\nHow it looks like\\nSome external repo he’s hosted?\\n\\nThere is more resources: How to proceed\\n1. All candidates will get training\\n2-Two people are selected to share coffe machine\\n?\\n\\n• Review by: Arzu Ucuncu,ase@dlr2u.com:\\n• RAI: Norfolk and Suffolk Clinical Commissioning Group - Research and Innovation CenterProject. Problem Identification:\\n   The main challenge for a patient in primary care is to find a proper diagnosis.\\n   This is because primary care doctors provide healthcare for a lot of patients\\n   or sometimes they provide global care for all patients with the items\\n   and not for a specific clinical problem - ie against vertigo. The problem\\n   is the inability of primary care health care doctors to provide an actual medical diagnosis and treatment.\\n   • Solutions:Instrumentation2017-ConfernceTalk-Presentation-Ques-tions   \\n• Impact: of being able to take a proper diagnosis of a vertigo - 2014-17 Global Links Disconnect   \\n   Laura Brown mentioned that primary care physicians perform approximately 250 000 patient visits on a publically funded national health system nationwide. This enables nurses to provide to the aging population healthcare services. [3]_3_An illustrative case: Nariotti\\nn:Clinical practice-based referencementat CIC -SighthospitalName not mentioned - Hospital pdf only\\n• Good things happen - some actual results to share\\n• can be translated to a clinical andresearch management framework\\n• Clinical Team: JDavid Rodgers\\n• Key Information: One diagnosis and one treatment across the patient population\\n• Research Team: Research and Innovation Center - primary care\\n• Impact: \\n• global impact only for global diseases – NDA.\\n• Future Impact:\\n• Potential approach for a Trial funding: Taking a 3-year effort\\n• Solution Approach: \\n• Data, Intervention and Research - clinical - trial testing\\n• Epidemiological health database.\\n• Other - IT unit - In order to visualise current healthcare budgets through the role of patient groups.\\n• IT unit - In order to track the state of the world and prevent patients from dying.\\n']\n",
      "Generated ICD-10 Codes for SUBJECT_ID 15992303: ['04 therapy, so after evaluation with characteristic\\nradiographic findings in the liver, transplutaminase and AST\\nsubsequently increased to 1200. Evaluation at the care unit indicated\\nelevated CRP, N/A and ferritin of 80. C. Hepatitis markers are positive\\nincluding S100, and 18-alpha globulin and IgM. Stones have been found\\non repeat parenchyma. \\n\\n     \\nPatient is scheduled for operative repair as emergency.\\n     \\nDignosed with Hepatitis A. \\n     \\nPractice Notes:\\nHepanmarerecapaderance \\nComplicacionssopomolardwasden arrivingin aspectos0\\nnasopharyngal sphere. Continued laparoscopic perforantenen on\\nA taper, and using regular 0,5 mg\\n\\n\\n     \\n          Status Post\\n       Liver Biopsy. NOTE:** long-term renal dialysis\\n       (ME).\\n       (ME)\\n       Stat\\n       Note:** **\\n     \\n           _______________________\\n   \\n \\n\\nSignals are more important than words in generating ICD codes\\n\\nFrontOpt: Elastic Forward Semantic Search in Scientific Paper Networks-With Dr L____ S______ from Stanford University\\n\\nStataware Internship:\\n\\nTill you learn, I’ll teach\\nThis place requires training its hardtakers\\n\\nTree plotting module: With Dr. J____ H____Yellowing of trees: replikaemonnode  (Forked to Fletcher NIH)\\n\\nMacroeconomic data visualisation: With Dr. L____ H____ teclusigent\\n\\nThe opportunity: RAI\\nauto generate ICD codes with the narrative text\\n\\nRais presentation\\nThe inaugaration\\n\\nAs a visual designer (Box free)\\nAs testing manager (same repo, with public key access).\\nHow it looks like\\nSome external repo he’s hosted?\\n\\nThere is more resources: How to proceed\\n1. All candidates will get training\\n2-Two people are selected to share coffe machine\\n?\\n\\n• Review by: Arzu Ucuncu,ase@dlr2u.com:\\n• RAI: Norfolk and Suffolk Clinical Commissioning Group - Research and Innovation CenterProject. Problem Identification:\\n   The main challenge for a patient in primary care is to find a proper diagnosis.\\n   This is because primary care doctors provide healthcare for a lot of patients\\n   or sometimes they provide global care for all patients with the items\\n   and not for a specific clinical problem - ie against vertigo. The problem\\n   is the inability of primary care health care doctors to provide an actual medical diagnosis and treatment.\\n   • Solutions:Instrumentation2017-ConfernceTalk-Presentation-Ques-tions   \\n• Impact: of being able to take a proper diagnosis of a vertigo - 2014-17 Global Links Disconnect   \\n   Laura Brown mentioned that primary care physicians perform approximately 250 000 patient visits on a publically funded national health system nationwide. This enables nurses to provide to the aging population healthcare services. [3]_3_An illustrative case: Nariotti\\nn:Clinical practice-based referencementat CIC -SighthospitalName not mentioned - Hospital pdf only\\n• Good things happen - some actual results to share\\n• can be translated to a clinical andresearch management framework\\n• Clinical Team: JDavid Rodgers\\n• Key Information: One diagnosis and one treatment across the patient population\\n• Research Team: Research and Innovation Center - primary care\\n• Impact: \\n• global impact only for global diseases – NDA.\\n• Future Impact:\\n• Potential approach for a Trial funding: Taking a 3-year effort\\n• Solution Approach: \\n• Data, Intervention and Research - clinical - trial testing\\n• Epidemiological health database.\\n• Other - IT unit - In order to visualise current healthcare budgets through the role of patient groups.\\n• IT unit - In order to track the state of the world and prevent patients from dying.\\n']\n",
      "\n",
      "ICD-10 Code Prediction Workflow Completed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Vertex AI configuration\n",
    "    PROJECT_ID = \"168237001903\"  # Replace with your GCP Project ID\n",
    "    ENDPOINT_ID = \"2125990394700234752\"  # Replace with your Endpoint ID\n",
    "    LOCATION = \"us-central1\"  # Replace with your endpoint region\n",
    "\n",
    "    print(\"\\nStarting ICD-10 Code Prediction Workflow...\\n\")\n",
    "\n",
    "    # Step 1: Fetch clinical notes from Snowflake\n",
    "    print(\"Step 1: Fetching clinical notes...\")\n",
    "    clinical_notes_df = fetch_clinical_notes()\n",
    "\n",
    "    # Step 2: Process each clinical note and generate ICD-10 codes\n",
    "    if not clinical_notes_df.empty:\n",
    "        print(\"Step 2: Processing clinical notes...\")\n",
    "        for _, row in clinical_notes_df.iterrows():\n",
    "            subject_id = row[\"SUBJECT_ID\"]\n",
    "            hadm_id = row[\"HADM_ID\"]\n",
    "            clinical_note = row[\"TEXT\"]\n",
    "\n",
    "            print(f\"\\nProcessing SUBJECT_ID: {subject_id}, HADM_ID: {hadm_id}\")\n",
    "            print(f\"Clinical Note: {clinical_note[:200]}...\")  # Display the first 200 characters\n",
    "\n",
    "            # Prepare instances with correct structure\n",
    "            instances = [{\"input\": clinical_note}]\n",
    "\n",
    "            # Generate ICD-10 codes using the Vertex AI endpoint\n",
    "            icd_codes = predict_icd_codes(\n",
    "                project=PROJECT_ID,\n",
    "                endpoint_id=ENDPOINT_ID,\n",
    "                location=LOCATION,\n",
    "                instances=instances\n",
    "            )\n",
    "\n",
    "            # Print the results\n",
    "            if icd_codes:\n",
    "                print(f\"Generated ICD-10 Codes for SUBJECT_ID {subject_id}: {icd_codes}\")\n",
    "            else:\n",
    "                print(f\"Failed to generate ICD-10 codes for SUBJECT_ID {subject_id}.\")\n",
    "    else:\n",
    "        print(\"No clinical notes found in the Snowflake table.\")\n",
    "\n",
    "    print(\"\\nICD-10 Code Prediction Workflow Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " meta-llama/Llama-3.1-8B-Instruct\n",
    " \n",
    " https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "SERVERLESS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"What is the capital of France?\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from huggingface_hub import InferenceClient\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOWFLAKE_USER = \"DOLPHIN\"\n",
    "SNOWFLAKE_PASSWORD = \"Maapaa@1603\"\n",
    "SNOWFLAKE_ACCOUNT = \"URB63596\"\n",
    "SNOWFLAKE_WAREHOUSE = \"ANIMAL_TASK_WH\"\n",
    "SNOWFLAKE_DATABASE = \"mimic_iv_medi_assist\"\n",
    "SNOWFLAKE_SCHEMA = \"staging_mimc\"\n",
    "DISCHARGE_TABLE = \"MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT SUBJECT_ID, HADM_ID, TEXT \n",
    "FROM MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\n",
    "WHERE TEXT IS NOT NULL\n",
    "LIMIT 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Connecting to Snowflake...\n",
      "[INFO] Executing query to fetch clinical notes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/v5dnvjg12ws3p1zszn_fvgt80000gn/T/ipykernel_1048/3369770645.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  clinical_notes_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] printing dataframe data...\n",
      "\n",
      "   SUBJECT_ID   HADM_ID                                               TEXT\n",
      "0    15992303  22502053   \\nName:  ___               Unit No:   ___\\n \\...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[INFO] Connecting to Snowflake...\")\n",
    "conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "    database=SNOWFLAKE_DATABASE,\n",
    "    schema=SNOWFLAKE_SCHEMA,)\n",
    "\n",
    "print(\"[INFO] Executing query to fetch clinical notes...\\n\")\n",
    "clinical_notes_df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n[INFO] printing dataframe data...\\n\")\n",
    "print(clinical_notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Initializing Hugging Face client...\n",
      "\n",
      "\n",
      "[INFO] Step 2: Processing clinical notes...\n",
      "====================================================================================\n",
      "\n",
      "[INFO] Processing SUBJECT_ID: 15992303 \n",
      "[INFO] Processing HADM_ID: 22502053\n",
      "\n",
      "[INFO] Formatting message for the model...\n",
      "\n",
      "[INFO] Sending request to the Hugging Face model...\n",
      "\n",
      " [INFO] completion...\n",
      "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='[\\n    {\"K70.9\": \"Chronic liver disease, unspecified\"},\\n    {\"R73.0\": \"Jaundice, unspecified\"},\\n    {\"K75.859A\": \"Acute hepatitis A with hepatic failure\"},\\n    {\"D69.3\": \"Hemophagocytic lymphohistiocytosis (HLH)\"},\\n    {\"B00.3\": \"Herpes simplex virus type 1 infection\"}\\n]', tool_calls=None), logprobs=None)], created=1732729906, id='', model='meta-llama/Llama-3.1-8B-Instruct', system_fingerprint='2.3.1-sha-a094729', usage=ChatCompletionOutputUsage(completion_tokens=91, prompt_tokens=5252, total_tokens=5343))\n",
      "\n",
      " [INFO] response...\n",
      "[\n",
      "    {\"K70.9\": \"Chronic liver disease, unspecified\"},\n",
      "    {\"R73.0\": \"Jaundice, unspecified\"},\n",
      "    {\"K75.859A\": \"Acute hepatitis A with hepatic failure\"},\n",
      "    {\"D69.3\": \"Hemophagocytic lymphohistiocytosis (HLH)\"},\n",
      "    {\"B00.3\": \"Herpes simplex virus type 1 infection\"}\n",
      "]\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "HF_API_KEY = \"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\"\n",
    "\n",
    "# Initialize the Hugging Face Inference Client\n",
    "print(\"\\n[INFO] Initializing Hugging Face client...\\n\")\n",
    "client = InferenceClient(api_key=HF_API_KEY)\n",
    "\n",
    "print(\"\\n[INFO] Step 2: Processing clinical notes...\")\n",
    "\n",
    "for _, row in clinical_notes_df.iterrows():\n",
    "    print(\"====================================================================================\")\n",
    "    subject_id = row[\"SUBJECT_ID\"]\n",
    "    hadm_id = row[\"HADM_ID\"]\n",
    "    clinical_note = row[\"TEXT\"]\n",
    "\n",
    "    print(f\"\\n[INFO] Processing SUBJECT_ID: {subject_id} \\n[INFO] Processing HADM_ID: {hadm_id}\")\n",
    "    \n",
    "    print(\"\\n[INFO] Formatting message for the model...\")\n",
    "\n",
    "    #TOP 10 ICD CODES\n",
    "    # message = [\n",
    "    #     {\n",
    "    #         \"role\": \"user\",\n",
    "    #         \"content\": f\"\"\"\n",
    "    #         You are an intelligent clinical language model specialized in generating ICD-10 codes.\n",
    "    #         Below is a patient's clinical note. Generate only the 10 most relevant ICD-10 codes as a Python list of strings. No explanation and code required in the output.\n",
    "\n",
    "    #         Clinical Note:\n",
    "    #         {clinical_note}\n",
    "\n",
    "    #         Return the output in the following format:\n",
    "\n",
    "    #         [\"ICD10_CODE_1\", \"ICD10_CODE_2\", \"ICD10_CODE_3\", ..., \"ICD10_CODE_10\"]\n",
    "    #         \"\"\"\n",
    "    #     }\n",
    "    # ]\n",
    "\n",
    "    # Generate top 5 ICD-10 codes with descriptions\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are an intelligent clinical language model specialized in generating ICD-10 codes.\n",
    "            Below is a patient's clinical note. Generate only the 5 most relevant ICD-10 codes along with their descriptions. No explanation or additional information is required in the output.\n",
    "\n",
    "            Clinical Note:\n",
    "            {clinical_note}\n",
    "\n",
    "            Return the output in the following format:\n",
    "            [\n",
    "                {{\"ICD10_CODE_1\": \"ICD10_CODE_1_DESCRIPTION\"}},\n",
    "                {{\"ICD10_CODE_2\": \"ICD10_CODE_2_DESCRIPTION\"}},\n",
    "                {{\"ICD10_CODE_3\": \"ICD10_CODE_3_DESCRIPTION\"}},\n",
    "                {{\"ICD10_CODE_4\": \"ICD10_CODE_4_DESCRIPTION\"}},\n",
    "                {{\"ICD10_CODE_5\": \"ICD10_CODE_5_DESCRIPTION\"}}\n",
    "            ]\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    print(\"\\n[INFO] Sending request to the Hugging Face model...\")\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        messages=message,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    print(\"\\n [INFO] completion...\")\n",
    "    print(completion)\n",
    "\n",
    "    icd_response = completion[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "    print(\"\\n [INFO] response...\")\n",
    "    print(icd_response)\n",
    "\n",
    "    print(\"====================================================================================\")\n",
    "    #print(f\"[DEBUG] Clinical Note: {clinical_note[:200]}...\")  # Show first 200 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Implementing GCP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account JSON key\n",
    "SERVICE_ACCOUNT_FILE = \"/Users/shreyajaiswal/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/vertex-ai.json\"\n",
    "\n",
    "# Authenticate using the service account\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "import google.auth.transport.requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required SCOPES\n",
    "SCOPES = ['https://www.googleapis.com/auth/cloud-platform']\n",
    "\n",
    "# Service account JSON file\n",
    "SERVICE_ACCOUNT_FILE = '/Users/shreyajaiswal/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/vertex-ai.json'\n",
    "\n",
    "# Vertex AI Configuration\n",
    "PROJECT_ID = \"168237001903\"\n",
    "ENDPOINT_ID = \"282329297245437952\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# Construct the Endpoint URL\n",
    "ENDPOINT_URL = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}:predict\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Authenticating with Google Cloud...\n"
     ]
    }
   ],
   "source": [
    "# Authenticate using the service account\n",
    "print(\"[INFO] Authenticating with Google Cloud...\")\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
    ")\n",
    "\n",
    "# Refresh credentials to obtain the bearer token\n",
    "auth_request = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_request)\n",
    "AUTH_TOKEN = credentials.token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake Configuration\n",
    "SNOWFLAKE_USER = \"DOLPHIN\"\n",
    "SNOWFLAKE_PASSWORD = \"Maapaa@1603\"\n",
    "SNOWFLAKE_ACCOUNT = \"URB63596\"\n",
    "SNOWFLAKE_WAREHOUSE = \"ANIMAL_TASK_WH\"\n",
    "SNOWFLAKE_DATABASE = \"mimic_iv_medi_assist\"\n",
    "SNOWFLAKE_SCHEMA = \"staging_mimc\"\n",
    "DISCHARGE_TABLE = \"MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake Query\n",
    "query = \"\"\"\n",
    "SELECT SUBJECT_ID, HADM_ID, TEXT \n",
    "FROM MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\n",
    "WHERE TEXT IS NOT NULL\n",
    "LIMIT 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connecting to Snowflake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/v5dnvjg12ws3p1zszn_fvgt80000gn/T/ipykernel_1048/2830517869.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  clinical_notes_df = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Clinical notes fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Connect to Snowflake and fetch clinical notes\n",
    "print(\"[INFO] Connecting to Snowflake...\")\n",
    "connection = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "    database=SNOWFLAKE_DATABASE,\n",
    "    schema=SNOWFLAKE_SCHEMA\n",
    ")\n",
    "\n",
    "try:\n",
    "    clinical_notes_df = pd.read_sql(query, connection)\n",
    "    print(\"[INFO] Clinical notes fetched successfully!\")\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[INFO] Processing SUBJECT_ID: 15992303, HADM_ID: 22502053\n",
      "[INFO] Sending request to Vertex AI...\n",
      "[ERROR] Failed to get prediction for SUBJECT_ID 15992303, HADM_ID 22502053\n",
      "Status Code: 500, Response: {\"error\":\"Incomplete generation\",\"error_type\":\"Incomplete generation\"}\n",
      "================================================================================\n",
      "[INFO] Workflow completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process each clinical note and send to Vertex AI\n",
    "for _, row in clinical_notes_df.iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    subject_id = row[\"SUBJECT_ID\"]\n",
    "    hadm_id = row[\"HADM_ID\"]\n",
    "    clinical_note = row[\"TEXT\"]\n",
    "\n",
    "    print(f\"[INFO] Processing SUBJECT_ID: {subject_id}, HADM_ID: {hadm_id}\")\n",
    "\n",
    "    # Prepare the instance payload with token configuration\n",
    "    payload = {\n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"inputs\": f\"\"\"\n",
    "                You are an intelligent clinical language model specialized in generating ICD-10 codes.\n",
    "                Below is a patient's clinical note. Generate only the 5 most relevant ICD-10 codes along with their descriptions. No explanation or additional information is required in the output.\n",
    "\n",
    "                Clinical Note:\n",
    "                {clinical_note}\n",
    "\n",
    "                Return the output in the following format:\n",
    "                [\n",
    "                    {{\"ICD10_CODE_1\": \"ICD10_CODE_1_DESCRIPTION\"}},\n",
    "                    {{\"ICD10_CODE_2\": \"ICD10_CODE_2_DESCRIPTION\"}},\n",
    "                    {{\"ICD10_CODE_3\": \"ICD10_CODE_3_DESCRIPTION\"}},\n",
    "                    {{\"ICD10_CODE_4\": \"ICD10_CODE_4_DESCRIPTION\"}},\n",
    "                    {{\"ICD10_CODE_5\": \"ICD10_CODE_5_DESCRIPTION\"}}\n",
    "                ]\n",
    "                \"\"\",\n",
    "                \"parameters\": {\n",
    "                    \"max_input_tokens\": 1500,\n",
    "                    \"max_output_tokens\": 1000\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Send the request to Vertex AI\n",
    "    try:\n",
    "        print(\"[INFO] Sending request to Vertex AI...\")\n",
    "        response = requests.post(ENDPOINT_URL, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            predictions = response.json().get(\"predictions\", [])\n",
    "            print(\"[INFO] Top 5 ICD Codes with Descriptions:\")\n",
    "            for prediction in predictions:\n",
    "                print(json.dumps(prediction, indent=2))\n",
    "        else:\n",
    "            print(f\"[ERROR] Failed to get prediction for SUBJECT_ID {subject_id}, HADM_ID {hadm_id}\")\n",
    "            print(f\"Status Code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] An error occurred while processing SUBJECT_ID {subject_id}, HADM_ID {hadm_id}: {e}\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"[INFO] Workflow completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_clinical_notes():\n",
    "    \"\"\"\n",
    "    Fetches clinical notes from the Snowflake table MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame containing SUBJECT_ID, HADM_ID, and TEXT.\n",
    "    \"\"\"\n",
    "    # Snowflake connection details\n",
    "    # Snowflake connection details\n",
    "    SNOWFLAKE_USER = \"DOLPHIN\"\n",
    "    SNOWFLAKE_PASSWORD = \"Maapaa@1603\"\n",
    "    SNOWFLAKE_ACCOUNT = \"URB63596\"\n",
    "    SNOWFLAKE_WAREHOUSE = \"ANIMAL_TASK_WH\"\n",
    "    SNOWFLAKE_DATABASE = \"mimic_iv_medi_assist\"\n",
    "    SNOWFLAKE_SCHEMA = \"staging_mimc\"\n",
    "    DISCHARGE_TABLE = \"MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT SUBJECT_ID, HADM_ID, TEXT \n",
    "    FROM MIMIC_IV_MEDI_ASSIST.STAGING_MIMIC.STG_DISCHARGE\n",
    "    WHERE TEXT IS NOT NULL\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(\"\\nConnecting to Snowflake...\")\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "        )\n",
    "        print(\"Executing query to fetch clinical notes...\")\n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        print(f\"Fetched {len(df)} records from Snowflake.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from Snowflake: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, max_length=2000):\n",
    "    \"\"\"\n",
    "    Truncates the input text to ensure it fits within the model's token limit.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input clinical note.\n",
    "        max_length (int): Maximum allowed length for the text in tokens.\n",
    "\n",
    "    Returns:\n",
    "        str: The truncated text.\n",
    "    \"\"\"\n",
    "    truncated = text[:max_length]\n",
    "    print(f\"[INFO] Truncated text to {len(truncated)} characters (max {max_length}).\")\n",
    "    return truncated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instance(note):\n",
    "    \"\"\"\n",
    "    Formats the clinical note with an instruction for ICD-10 code generation.\n",
    "\n",
    "    Args:\n",
    "        note (str): The input clinical note.\n",
    "\n",
    "    Returns:\n",
    "        dict: The formatted instance for the model.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a clinical language model specialized in generating ICD-10 codes.\n",
    "    Below is a clinical note. Analyze it and generate the top 10 most relevant ICD-10 codes.\n",
    "\n",
    "    Clinical Note:\n",
    "    {note}\n",
    "\n",
    "    Please return the ICD-10 codes as a Python list of strings.\n",
    "    \"\"\"\n",
    "    return {\"inputs\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_icd_codes(project, endpoint_id, location, clinical_notes):\n",
    "    \"\"\"\n",
    "    Sends clinical notes to a Vertex AI endpoint and retrieves ICD-10 code predictions.\n",
    "\n",
    "    Args:\n",
    "        project (str): GCP project ID.\n",
    "        endpoint_id (str): Vertex AI endpoint ID.\n",
    "        location (str): Location of the endpoint (e.g., \"us-central1\").\n",
    "        clinical_notes (list): List of clinical notes to process.\n",
    "\n",
    "    Returns:\n",
    "        list: Predictions from the model for each note.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\nInitializing Vertex AI client...\")\n",
    "        aiplatform.init(project=project, location=location)\n",
    "\n",
    "        # Load the endpoint\n",
    "        print(f\"Loading endpoint: projects/{project}/locations/{location}/endpoints/{endpoint_id}\")\n",
    "        endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project}/locations/{location}/endpoints/{endpoint_id}\")\n",
    "\n",
    "        predictions = []\n",
    "        for note in clinical_notes:\n",
    "            # Format the payload\n",
    "            # Format the payload\n",
    "            instance = format_instance(truncate_text(note, max_length=1900))  # Reserve tokens for max_new_tokens\n",
    "            print(f\"Sending prediction request for clinical note: {note[:200]}...\")  # Show the first 200 characters\n",
    "\n",
    "            # Send the prediction request\n",
    "            response = endpoint.predict(instances=[instance], parameters={\"max_new_tokens\": 128})\n",
    "            predictions.append(response.predictions[0])  # Assume the model returns a list of predictions\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error generating predictions: {error}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Starting ICD-10 Code Prediction Workflow...\n",
      "\n",
      "[INFO] Step 1: Fetching clinical notes...\n",
      "\n",
      "Connecting to Snowflake...\n",
      "Executing query to fetch clinical notes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/v5dnvjg12ws3p1zszn_fvgt80000gn/T/ipykernel_6027/3658030873.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 10 records from Snowflake.\n",
      "[INFO] Step 2: Processing clinical notes...\n",
      "\n",
      "[INFO] Sending clinical notes for prediction...\n",
      "\n",
      "Initializing Vertex AI client...\n",
      "Loading endpoint: projects/168237001903/locations/us-central1/endpoints/6289568250204258304\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___               Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Amoxicillin / azithromy...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___                 Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Patient recorded as h...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___                 Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Patient recorded as h...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___                 Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "No Known Allergies / ...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___                Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: CARDIOTHORACIC\n",
      " \n",
      "Allergies: \n",
      "Aspartame\n",
      " \n",
      "Atte...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___               Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Atenolol\n",
      " \n",
      "Attending: _...\n",
      "[INFO] Truncated text to 1900 characters (max 1900).\n",
      "Sending prediction request for clinical note:  \n",
      "Name:  ___               Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Keflex / Augmentin / Zo...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Generate ICD-10 codes using the Vertex AI endpoint\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Sending clinical notes for prediction...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m icd_codes_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_icd_codes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mENDPOINT_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclinical_notes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclinical_notes\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 30\u001b[0m, in \u001b[0;36mpredict_icd_codes\u001b[0;34m(project, endpoint_id, location, clinical_notes)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending prediction request for clinical note: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnote[:\u001b[38;5;241m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Show the first 200 characters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Send the prediction request\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mpredictions[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assume the model returns a list of predictions\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/google/cloud/aiplatform/models.py:2341\u001b[0m, in \u001b[0;36mEndpoint.predict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[1;32m   2333\u001b[0m         predictions\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   2334\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2337\u001b[0m         model_version_id\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelVersionId\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   2338\u001b[0m     )\n\u001b[1;32m   2340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2341\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[1;32m   2348\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mMessageToDict(prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:853\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Start-to-Complete/MediAssist-Healthcare-Data-Solutions/.venv/lib/python3.9/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Vertex AI configuration\n",
    "# Vertex AI endpoint details\n",
    "    PROJECT_ID = \"168237001903\"  # Replace with your GCP Project ID\n",
    "    ENDPOINT_ID = \"6289568250204258304\"  # Replace with your Endpoint ID\n",
    "    LOCATION = \"us-central1\"  # Replace with your endpoint region\n",
    "\n",
    "    print(\"\\n[INFO] Starting ICD-10 Code Prediction Workflow...\\n\")\n",
    "\n",
    "    # Step 1: Fetch clinical notes from Snowflake\n",
    "    print(\"[INFO] Step 1: Fetching clinical notes...\")\n",
    "    clinical_notes_df = fetch_clinical_notes()\n",
    "\n",
    "    # Step 2: Process each clinical note and generate ICD-10 codes\n",
    "    if not clinical_notes_df.empty:\n",
    "        print(\"[INFO] Step 2: Processing clinical notes...\\n\")\n",
    "\n",
    "        # Extract clinical notes from the DataFrame\n",
    "        clinical_notes = clinical_notes_df[\"TEXT\"].tolist()\n",
    "\n",
    "        # Generate ICD-10 codes using the Vertex AI endpoint\n",
    "        print(\"[INFO] Sending clinical notes for prediction...\")\n",
    "        icd_codes_predictions = predict_icd_codes(\n",
    "            project=PROJECT_ID,\n",
    "            endpoint_id=ENDPOINT_ID,\n",
    "            location=LOCATION,\n",
    "            clinical_notes=clinical_notes\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        print(\"\\n[INFO] Results:\")\n",
    "        for idx, row in clinical_notes_df.iterrows():\n",
    "            subject_id = row[\"SUBJECT_ID\"]\n",
    "            hadm_id = row[\"HADM_ID\"]\n",
    "            icd_codes = icd_codes_predictions[idx] if idx < len(icd_codes_predictions) else None\n",
    "\n",
    "            print(f\"\\n[RESULT] SUBJECT_ID: {subject_id}, HADM_ID: {hadm_id}\")\n",
    "            if icd_codes:\n",
    "                print(f\"[RESULT] Generated ICD-10 Codes: {icd_codes}\")\n",
    "            else:\n",
    "                print(\"[WARNING] Failed to generate ICD-10 codes for this clinical note.\")\n",
    "    else:\n",
    "        print(\"[WARNING] No clinical notes found in the Snowflake table.\")\n",
    "\n",
    "    print(\"\\n[INFO] ICD-10 Code Prediction Workflow Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content='The capital of France is Paris!', tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"What is the capital of France?\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " meta-llama/Llama-3.1-8B-Instruct\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
